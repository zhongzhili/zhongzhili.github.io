---
title: "Reading Notes of Paper"
date: 2023-12-18
author: Zhongzhi Li
slug: first-post
draft: false
toc: true
categories:
  - test
tags:
  - article
  - English
---

{{<block class="reminder">}}

Article [link](https://tidel.mie.utoronto.ca/pubs/tracegen_camera_20210926.pdf) if you are interested.

{{<end>}}

# Request sequence generation of VM
## Article title

Generating Complex, Realistic Cloud Workloads using Recurrent Neural Networks

## Author and organization

Shane Bergsma (Huawei Canada Research Center), Timothy Zeyl (Huawei Canada Research Center), Arik Senderovich (University of Toronto), J. Christopher Beck (University of Toronto)

## Problems solved by the article

<p style="text-align: justify;">To predict the load of virtual machines dynamically created by users on the cloud, a Cloud Workload can be simply regarded as a Trace of VMs created by users. Each record records the creation time of the VM and the number of resources requested by the VM (CPU, Memory, Network, etc.), VM survival time, etc.</p>

<p style="text-align: justify;">If the algorithm can accurately predict how the workload will change in the future, resource allocation can be planned more accurately. The accurate prediction model can also be used to tune the scheduling algorithm, improve resource utilization, etc.</p>

## Part of the difficulty with this problem

<p style="text-align: justify;">One of the difficulties is that historical data cannot be used directly for prediction and optimization:</p>

<p style="text-align: justify;">The amount of historical data is not large enough. For example, a scheduler based on reinforcement learning requires large batches of data;</p>

<p style="text-align: justify;">Historical data has limitations. It contains limited information and cannot be used for long-term load forecasting;</p>

## Limitations of other approaches to the problem

<p style="text-align: justify;">Traditional modeling method:</p>

<p style="text-align: justify;">It is assumed that the time when a user creates a VM follows an independent Poisson distribution;</p>

<p style="text-align: justify;">It is assumed that user demand for resources follows an independent polynomial distribution;</p>

<p style="text-align: justify;">It is assumed that the life cycle of each VM (or Job) is also independent of each other.</p>

<p style="text-align: justify;">Various independence assumptions in traditional modeling methods make the fitting between modeling results and real data low, making it difficult to generate real, high-quality workloads, resulting in inaccurate final decisions.</p>

## The idea of the method proposed in the article

<p style="text-align: justify;">This paper introduces a predictive model for large-scale cloud workloads that captures long-distance inter-job correlations in terms of arrival rates, resource requirements, and lifetimes. The workload is modeled as a three-stage generation process with three separate models: (1) predicting the number of batch arrivals over time (Batch Arrival Modeling), (2) predicting the order in which resources are requested (Resource Modeling), and (3) predicting life cycle (Lifetime Modeling). Figure 1 shows the calculation framework of the algorithm. It takes historical data as input and passes through three models. Each model uses the output of the previous model as the input of the current model. Finally, a Trace is generated, which contains the creation of each VM. time, end time, and request for resources.</p>

{{<figure src="https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-1.png" title="Figure 1. Three-stage workload generation process in a cycle" width="260">}}

Next, the three stages will be analyzed in turn:

**Batch Arrival Modeling**

<p style="text-align: justify;">The first model uses Poisson regression to generate the number of batches arriving within a period of time (e.g. 5 min) (a batch is defined as all jobs submitted by the same user within this period of time).</p>

{{<figure src="https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-2.png" width="500">}}

Poisson regression model establishment:

<p style="text-align: justify;">Non-homogeneous Poisson regression assumes that the number of events `N_p` occurring in each time period is modeled by a Poisson distribution with a mean of `\mu_{p}`, and its expression is `\mu_{p}=\exp \left(\mathbf{w} \cdot \mathbf{x}_{\mathbf{p}}\right)`, where `x_p` is a feature vector and `w` is a parameter to be optimized vector. Given some training data consisting of an event number vector `y` and a feature vector matrix `X`, fit the parameters by minimizing the negative log-likelihood (NLL) of the training data:
`\begin{align}
\text { Loss } & =-\log (\operatorname{Pr}(\mathbf{y} \mid \mathbf{X}, \mathbf{w})) \\
& =\sum_{p} \mu_{p}-y_{p} \log \left(\mu_{p}\right)
\end{align}`

## Math

For example, 

`$1 + 1 = 3$`

You can add Tags & References:

`$$p(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp \left(-\frac{1}{2}\left[\frac{x-\mu}{\sigma}\right]^2\right)\tag{1.1}\label{eq1.1}$$`

Aligning equations[^3] are also possible, 

`\begin{align}
\sqrt{37} & = \sqrt{\frac{73^2-1}{12^2}} \\
 & = \sqrt{\frac{73^2}{12^2}\cdot\frac{73^2-1}{73^2}} \\ 
 & = \sqrt{\frac{73^2}{12^2}}\sqrt{\frac{73^2-1}{73^2}} \\
 & = \frac{73}{12}\sqrt{1 - \frac{1}{73^2}} \\ 
 & \approx \frac{73}{12}\left(1 - \frac{1}{2\cdot73^2}\right)
\end{align}`