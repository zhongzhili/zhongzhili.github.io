<a name=top></a><!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Zhongzhi-Li</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/bash.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js></script><script src=https://cdn.jsdelivr.net/npm/vega@5.17.0></script><script src=https://cdn.jsdelivr.net/npm/vega-lite@4.17.0></script><script src=https://cdn.jsdelivr.net/npm/vega-embed@6.12.2></script><script>hljs.initHighlightingOnLoad();</script><link rel=icon href=https://zhongzhili.github.io/media/personal-logo.png></head><body><div class=wrapper><header class=header><nav class=nav><a href=/ class=nav-logo><img src=/media/personal-logo.png width=50 height=50 alt=Hugo-ht></a><ul class=nav-links><li><a href=/>Home</a></li><li><a href=/en/about/>About</a></li><li><a href=/en/posts/>Posts</a></li><li><a href=/cn/posts/>‰∏≠Êñá</a></li></ul></nav></header><main class=content role=main><div style=text-align:center><h1>Reading Notes of Paper</h1><p>Zhongzhi Li
/ 2023-12-18</p><hr></div><span class=article-toolbar><a href=https://github.com/zhongzhili/zhongzhili.github.io/edit/master/content/en/posts/2023-12-18-Paper.md style=font-size:24px;color:#000 target=_blank><i class="fa fa-edit" aria-hidden=true title="Suggest an edit of this page"></i></a></span><aside class=toc>Table of Contents:<nav id=TableOfContents><ol><li><a href=#article-title>Article title</a></li><li><a href=#author-and-organization>Author and organization</a></li><li><a href=#problems-solved-by-the-article>Problems solved by the article</a></li><li><a href=#part-of-the-difficulty-with-this-problem>Part of the difficulty with this problem</a></li><li><a href=#limitations-of-other-approaches-to-the-problem>Limitations of other approaches to the problem</a></li><li><a href=#the-idea-of-the-method-proposed-in-the-article>The idea of the method proposed in the article</a></li><li><a href=#math>Math</a></li></ol></nav></aside><div class="body-text list-text"><div class=reminder><p>Article <a href=https://tidel.mie.utoronto.ca/pubs/tracegen_camera_20210926.pdf target=_blank rel="noreferrer noopener">link</a>
if you are interested.</p></div><h1 id=request-sequence-generation-of-vm>Request sequence generation of VM<a href=#request-sequence-generation-of-vm class=header-anchor arialabel=Anchor> #</a></h1><h2 id=article-title>Article title<a href=#article-title class=header-anchor arialabel=Anchor> #</a></h2><p>Generating Complex, Realistic Cloud Workloads using Recurrent Neural Networks</p><h2 id=author-and-organization>Author and organization<a href=#author-and-organization class=header-anchor arialabel=Anchor> #</a></h2><p>Shane Bergsma (Huawei Canada Research Center), Timothy Zeyl (Huawei Canada Research Center), Arik Senderovich (University of Toronto), J. Christopher Beck (University of Toronto)</p><h2 id=problems-solved-by-the-article>Problems solved by the article<a href=#problems-solved-by-the-article class=header-anchor arialabel=Anchor> #</a></h2><p style=text-align:justify>To predict the load of virtual machines dynamically created by users on the cloud, a Cloud Workload can be simply regarded as a Trace of VMs created by users. Each record records the creation time of the VM and the number of resources requested by the VM (CPU, Memory, Network, etc.), VM survival time, etc.</p><p style=text-align:justify>If the algorithm can accurately predict how the workload will change in the future, resource allocation can be planned more accurately. The accurate prediction model can also be used to tune the scheduling algorithm, improve resource utilization, etc.</p><h2 id=part-of-the-difficulty-with-this-problem>Part of the difficulty with this problem<a href=#part-of-the-difficulty-with-this-problem class=header-anchor arialabel=Anchor> #</a></h2><p style=text-align:justify>One of the difficulties is that historical data cannot be used directly for prediction and optimization:</p><p style=text-align:justify>The amount of historical data is not large enough. For example, a scheduler based on reinforcement learning requires large batches of data;</p><p style=text-align:justify>Historical data has limitations. It contains limited information and cannot be used for long-term load forecasting;</p><h2 id=limitations-of-other-approaches-to-the-problem>Limitations of other approaches to the problem<a href=#limitations-of-other-approaches-to-the-problem class=header-anchor arialabel=Anchor> #</a></h2><p style=text-align:justify>Traditional modeling method:</p><p style=text-align:justify>It is assumed that the time when a user creates a VM follows an independent Poisson distribution;</p><p style=text-align:justify>It is assumed that user demand for resources follows an independent polynomial distribution;</p><p style=text-align:justify>It is assumed that the life cycle of each VM (or Job) is also independent of each other.</p><p style=text-align:justify>Various independence assumptions in traditional modeling methods make the fitting between modeling results and real data low, making it difficult to generate real, high-quality workloads, resulting in inaccurate final decisions.</p><h2 id=the-idea-of-the-method-proposed-in-the-article>The idea of the method proposed in the article<a href=#the-idea-of-the-method-proposed-in-the-article class=header-anchor arialabel=Anchor> #</a></h2><p style=text-align:justify>This paper introduces a predictive model for large-scale cloud workloads that captures long-distance inter-job correlations in terms of arrival rates, resource requirements, and lifetimes. The workload is modeled as a three-stage generation process with three separate models: (1) predicting the number of batch arrivals over time (Batch Arrival Modeling), (2) predicting the order in which resources are requested (Resource Modeling), and (3) predicting life cycle (Lifetime Modeling). Figure 1 shows the calculation framework of the algorithm. It takes historical data as input and passes through three models. Each model uses the output of the previous model as the input of the current model. Finally, a Trace is generated, which contains the creation of each VM. time, end time, and request for resources.</p><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><a href=https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-1.png itemprop=contentUrl><img itemprop=thumbnail src=https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-1.png width=260></a><figcaption><h4>Figure 1. Three-stage workload generation process in a cycle</h4></figcaption></figure><p>Next, the three stages will be analyzed in turn:</p><p><strong>Batch Arrival Modeling</strong></p><p style=text-align:justify>The first model uses Poisson regression to generate the number of batches arriving within a period of time (e.g. 5 min) (a batch is defined as all jobs submitted by the same user within this period of time).</p><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><a href=https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-2.png itemprop=contentUrl><img itemprop=thumbnail src=https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-2.png width=500></a></figure><p>Poisson regression model establishment:</p><p style=text-align:justify>Non-homogeneous Poisson regression assumes that the number of events `N_p` occurring in each time period is modeled by a Poisson distribution with a mean of `\mu_{p}`, and its expression is `\mu_{p}=\exp \left(\mathbf{w} \cdot \mathbf{x}_{\mathbf{p}}\right)`, where `x_p` is a feature vector and `w` is a parameter to be optimized vector. Given some training data consisting of an event number vector `y` and a feature vector matrix `X`, fit the parameters by minimizing the negative log-likelihood (NLL) of the training data:
`\begin{align}
\text { Loss } & =-\log (\operatorname{Pr}(\mathbf{y} \mid \mathbf{X}, \mathbf{w})) \\
& =\sum_{p} \mu_{p}-y_{p} \log \left(\mu_{p}\right)
\end{align}`<p>The article adds an elastic network regularization term to this loss function to constrain parameters, reduce model complexity, and reduce the risk of overfitting of the model.</p><p>The feature vector matrix X contains three types of time feature information:</p><p>HOD: Hour-of-day, from 1 to 24 (one-hot-encoded);</p><p>DOW: Day-of-week, from 1 to 7 (one-hot-encoded);</p><p>DOH: Day-of-history, from 1 to <code>ùëÅ</code> (survival-encoded), where there are <code>ùëÅ</code> total days in the history;</p><p><strong>Resource Modeling</strong></p><p>The second model uses LSTM to generate flavors (i.e. requested resource types, such as CPU, Memory) for all jobs within a period of time.</p><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><a href=https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-3.png itemprop=contentUrl><img itemprop=thumbnail src=https://raw.githubusercontent.com/zhongzhili/zhongzhili.github.io/master/content/en/fig/20231218-3.png width=500></a></figure><p>At each calculation step <code>t</code>, the Flavor LSTM returns a distribution containing <code>K</code> (<code>K</code> is 16) possible flavors, and a special end-of-batch (EOB) token to indicate a user&rsquo;s set of job requests over a period of time. The LSTM generates vectors of length <code>ùêæ+1</code>, which are fed into the softmax function, which returns in step <code>t</code>, the multinomial distribution over the <code>ùêæ</code> species label to which the flavor belongs:</p><p><code>$$\operatorname{Pr}\left(\hat{f}_t=k \mid \mathbf{y}_t\right)=\frac{\exp \left(y_t^k\right)}{\sum_{k^{\prime}=1}^{K+1} \exp \left(y_t^{k^{\prime}}\right)}$$</code></p><p>The standard method of minimizing the negative log-likelihood of training data (CrossEntropyLoss) is used to optimize the adjustment parameters. The loss value of the article is the cross-entropy loss value plus the value of the regularization penalty term, and then the parameters are optimized through gradient backpropagation.</p><p>The main flavor feature at step t is one-hot encoding of the flavor from the previous step <code>ùë°‚àí1</code>. If the previous step was the end of the batch, or the first flavor in the sequence is being generated, then pass the EOB token as input.</p><h2 id=math>Math<a href=#math class=header-anchor arialabel=Anchor> #</a></h2><p>For example,</p><p><code>$1 + 1 = 3$</code></p><p>You can add Tags & References:</p><p><code>$$p(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp \left(-\frac{1}{2}\left[\frac{x-\mu}{\sigma}\right]^2\right)\tag{1.1}\label{eq1.1}$$</code></p><p>Aligning equations[^3] are also possible,</p><p><code>\begin{align} \sqrt{37} & = \sqrt{\frac{73^2-1}{12^2}} \\ & = \sqrt{\frac{73^2}{12^2}\cdot\frac{73^2-1}{73^2}} \\ & = \sqrt{\frac{73^2}{12^2}}\sqrt{\frac{73^2-1}{73^2}} \\ & = \frac{73}{12}\sqrt{1 - \frac{1}{73^2}} \\ & \approx \frac{73}{12}\left(1 - \frac{1}{2\cdot73^2}\right) \end{align}</code></p><p style=color:#777>Last modified on 2023-12-18</p></div><a href=#top><i class="fa fa-chevron-up" style=font-size:30px;color:#000></i></a></main><footer class=footer><script type=text/javascript src=/js/math-code.js></script><script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=text/javascript src=/js/center-img.js></script><ul class=footer-links><li><a href=/en/posts/index.xml type=application/rss+xml title="RSS feed">Subscribe</a></li><li><a href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>License
<i class="fa fa-cc" aria-hidden=true title="Attribution-NonCommercial-ShareAlike 4.0 International"></i></a></li></ul><div class=copyright-text>¬©
Zhongzhi Li
2022-2023</div></footer>